# Открытый студенческий конкурс (хакатон) по быстрому прототипированию решений Интернета вещей с применением интерфеса "Мозг-компьютер"


##Содержание

- [Аннотация](#0)
- [1. Введение](#1)
	- [1.1. Инфраструктура типового решения IoT](#11)
	- [1.2. Интерфейс "мозг-компьютер" на основе вызванной волны P300](#12)
		- [1.2.1. Интерфейсы на основе мю-ритма](#121)
		- [1.2.2. Интерфейсы на основе альфа-ритма](#122)
		- [1.2.3. Интерфейсы на основе SSVEP и айтрекинг](#123)
		- [1.2.4. Интерфейсы, использующие P300](#124)
	- [1.3. Облачная платформа *Bluemix*](#13)
	- [1.4. Краткое описание концепций *Bluemix*](#14)
		- [1.4.1. Развертывание и управление приложением](#141)
		- [1.4.2. Сервисы DevOps Services для *Bluemix*](#142)
		- [1.4.3. Среда визуальной разработки JavaScript приложений Node-RED](#143)
		- [1.4.4. Терминология Node-RED](#144)
		- [1.4.5. Пример использования Node-RED](#145)
- [2. Принцип действия электроэнцефалографа](#2)
	- [2.1. Основы электроэнцефалографии головного мозга человека](#21)
	- [2.2. Восьмиканальный электроэнцефалограф ИНЭУМ им.И.С.Брука](#22)
- [3. Нейронные сети](#3)
	- [3.1 Немного теории](#31)
	- [3.2 Как выбрать топологию нейронной сети?](#32)
	- [3.3 Бибилиотека PyBrain ](#33)
- [Raspberry Pi](#4)
	- [Описание](#41)
		- [Порты и аппаратные интерфейсы](#411)
		- [Распиновка платы](#412)
		- [Питание](#413)
	- [Разбор тестового примера:](#42) 
	- [Настройка SSH соединения с Raspberry Pi](#43)
	- [Как узнать адрес Raspberry?](#44)
	- [Полезные команды для работы в ОС Raspbian](#45)
	- [Программирование](#46)
	- [//ToDo Подключение электроэнцефалографа к Raspberry](#47)
	- [//ToDo Взаимодействие с ЭЭГ на Raspberry](#48)
		- [//ToDo](#481)
		- [//ToDo](#482)
		- [//ToDo](#483)
- [Работа с IBM Bluemix](#5)
	- [Регистрация в Bluemix](#51)
	- [Создание приложения Node.js](#52)
	- [Подключение сервиса Watson IOT](#53)
	- [Принципы обмена MQTT-сообщениями в Bluemix и создание MQTT Device и MQTT API key](#54)
	- [Описание подключения к MQTT брокеру и проверка передачи MQTT сообщений с помощью MQTTlens](#55)
	- [//ToDo Визуализация данных ЭЭГ](#56)
- [//ToDo Тренажер управления инвалидной коляской](#6)
	- [//ToDo](#61)
	- [//ToDo](#62)
	- [//ToDo](#63)
- [//ToDo Основной алгоритм управления системой и тестирование проекта ИМК](#7)
	- [//ToDo](#71)
	- [//ToDo](#72)
	- [//ToDo](#73)
- [Дополнительная литература](#a001)

# Аннотация <a name="0"></a>

> Всем участникам соревнования предоставляется необходимое оборудование для реализации прототипа решения Интернета вещей и интерфеса мозг-компьютер: цифровой электроэнцефалограф, микрокомпьютеры, средства сопряжения. 

> В ходе соревнования типовой проект может быть использован для построения широкого спектра решений: 

> - в медицине; 

> - на отвтсвенном производстве; 

> - в бытовых условиях; 

> - транспорте и других областях.

> Задача для участников соревнования ставится следующим образом: **используя имеющийся набор сбора электроэнефалограммы головного мозга, микрокомпьютеры, облачные сервисы и приложения, разработать прототип распределенной системы Интернета вещей на основе ИМК.** 

> Допускается применение иных облачных платформ и аппаратно-программных решений. Прототип системы будет собран на специальном стенде в лаборатории IoT МГТУ им. Баумана, где он может быть продемонстрирован жюри. 



****
#1. Введение <a name="1"></a>

Воплощение потенциала идей, заложенных в концепцию Интернета вещей, способно существенно изменить уклад современной экономики. Благодаря внедрению масштабируемых облачных решений, использованию большого количества датчиков и распределенных микропроцессорных систем уже в ближайшее время могут быть созданы прорывные решения в таких областях, как: транспорт, сельское хозяйство, промышленное производство, здравоохранение, социальная сфера, быт и других. Все большее количество компаний обращает внимание на применение идей и технологий Интернета вещей для внедрения аналитики их деятельности и поиска новых возможностей для продуктов и услуг.

> *Интернет вещей (англ. Internet of Things, IoT) — это концепция вычислительной сети физических объектов («вещей»), оснащённых встроенными технологиями для взаимодействия друг с другом или с внешней средой.*
> 

Перечислим некоторые интересные факты:
-   По оценкам специалистов, к 2020 году к сети Интернет будет подключено до 50 млрд устройств, 20 млрд из них будут задействованы в инфраструктуре IoT.

![Прогноз количества устройств, подключенных к сети Интернет](assets/intro01.jpg)

-   До 90% данных, анализируемых устройствами Интернета вещей ранее не подвергались обработке.
-   До 60% данных, получаемых устройствами Интернета вещей, остаются актуальными лишь несколько миллисекунд.
-   В настоящее время только 0,1% устройств, способных выполнять полезную вычислительную нагрузку, подключены к сети.


Применение интерфейса мозг-компьютер (ИМК) в системах Интернета вещей в перспективе позволит устранить имеющиеся недостатки современных информационных и управляющих систем при взаимодейтсвии с человеком: т.е. необходимость обработки мышечной активности человека в качестве информации о реакции на внешние события. Целями передовых исследований и разработок коллективов ученых в области ИМК является расширение участия человека в принятии решений в кибер-физических системах, что способно существенно расширить их функциональность. Поэтому в нашем хакатоне мы также используем элементы ИМК, в частности, элекроэнцефалографы для анализа реакции человека на возникающие события. 


****
## 1.1. Инфраструктура типового решения IoT <a name="11"></a>

> 
>Под типовым решением Интернета вещей в данном конкурсе понимается распределенная кибер-физическая система, интегрирующая вычислительные ресурсы в физические процессы. В такой системе должны быть реализованы следующие основные функции:
> 

-   Сбор первичных данных с помощью сенсоров, расположенных в непосредственной близости от реальных объектов.
-   Управление объектами через актуаторы, подключенные к микрокомпьютерам.
-   Передача первичных данных от микрокомпьютеров в вычислительный хаб и в обратном направлении.
-   Первичная обработка данных в вычислительном хабе, формирование пакетов данных для передачи их в облако.
-   Получение и хранение данных в облаке.
-   Аналитическая обработка в облаке и формирование ключевых показателей эффективности (KPI) на основе данных об объектах, данных от сторонних источников, исторических данных.
-   Визуализация данных и результатов анализа на различных платформах: мобильных устройствах, носимой электронике, планшетах, компьютерах,     мониторах и пр.
-   Прием команд от внешних управляющих консолей.
-   Принятие решений на основе KPI и команд, выработка управляющих и информационных сообщений для актуаторов.
-   Передача управляющих сообщений в вычислительные хабы.

Примером подобной системы является структура, представленная на следующем рисунке.

![Пример решения Интернета вещей](assets/intro03.png)
**Пример решения Интернета вещей**

> 
> Мы используем в качестве примера автоматизированную систему для тренинга управления инвалидной коляскойна основе ИМК.***
> 

В примере использовано оборудование:

-   ЭЭГ (электроэнцефалограф), прибор для исследования активности головного мозга путем детектирования электрических импульсов, исходящих из различных его областей. 
-   Микрокомпьютеры на основе микроконтроллера STM32 раположен непосредственно внутри ЭЭГ прибора и служит для первичной обработки потенциалов электродов в цифровой код и их передачу вычислительному хабу.
-   Микрокомпьютер RaspberryPi используется в качестве вычислительного хаба.
-   Монитор используется для в качестве информационного табло для предъявления зрительных образов.
-   Облачная платформа IBM Bluemix для реализации сервисов хранения, аналитической обработки и визуализации данных.

Система работает следующим образом. 


![Функциональная схема проекта](assets/Intro031.png)
**Функциональная схема проекта**


-	Работой всей системы управляет Основная программы, работающей на хабе (микрокомьютере RaspberryPi).
-	Цикл управления начинается с предъявленния человеку зрительного образа команды через монитор, подключенный к хабу. В хакатоне будет использован доступ графическому экрану хаба по протоколу `VNC` (например, с помощью программы VNCViewer). В качестве команд предъявляются поочередно два изображения: "Стрелка влево" и "Стрелка вправо", символизирующие поворото инвалидной коляски влево и вправо.
-	Человек, обученный методике P300, задумывает необходимую ему команду и мысленно отвечает "ДА" в тот момент, когда команда появляется на экране. В этом случае приблизительно через 300 мс после предъявления мозг человека активно реагирует на него вызванной волной P300.
-	С помощью ЭЭГ потенциалы от трех электродов обрабатываются (фильтруются от посторонних сигналов и наведенных потенциоалов), и передаются в виде пакетов данных через интерфейс USB в вычислительный хаб. 
-	Через 100 мс после предъявления данные ЭЭГ начинают накапливаться в программном FIFO буфере хаба, реализованном в Python. 
- 	По прошествии 500 мс от начала предъявления (данные принимаются в течении 400 мс для учета индивидуальных особенностей мозговой активности человека) прием данных заканчивается и пакет данных передается на искусственнуюнейронную сеть.
-	Режимом работы нейронной сети управляет приложение в облачной платформе `Bluemix`. Доступны два режима работы: обучение нейронной сети, рабочий режим. На веб-странице `Консоли управления` с помощью броузера возможно изменить режим работы. В таком случае режим передается в вычислительный хаб.
-	Нейронная сеть принимает данные из FIFO и классифицирует наличие (или отсутствие) вызванной волны P300.
-	Информация о результате классификации, а также первичные данные от ЭЭГ, передаются в Консоль управления.
-	Информация о результате классификации передается в приложение, имитирующее 3D движение инвалидной коляски в пространстве. В результате выполняет изменение сцены движения с оответствии с поступившей командой.
-	После завершения обработки предыдущей команды, Основная программа переходит к выдаче следующей команды.
 

****

## 1.2. Интерфейс "мозг-компьютер" на основе вызванной волны P300<a name="12"></a>

Основноей целью применения ИМК является получение компьютерной системой однозначно интерпретируемых команд непосредственно от головного мозга без использования мышечной активности. Для разработки ИМК следует рассматривать три основные парадигмы ([1](#pub1)):

- ***Неинвазивный ИМК, основанный на распознавании ментальных состояний***, вызванных воображаемым выполнением движений. Он обеспечивает формирование дискретных управляющих команд и требует минимального времени обучения оператора при достаточно высокой производительности.

- ***Неинвазивный ИМК, использующий принцип непрерывного управления***. После выработки навыка управления, такой ИМК позволяет управлять внешним устройством как собственным (виртуальным) исполнительным органом, не требуя ментального кодирования дискретного набора команд.

- ***Инвазивный ИМК, основанный на двусторонней связи мозг-компьютер*** посредством имплантируемых электродов и позволяющий полностью инкорпорировать внешние технические устройства во внутреннюю нейронную модель схемы тела и, соответственно, оперировать с ними так же, как и с естественными исполнительными
органами. 

> 
>В хакатоне нами будут применятся неинвазивные ИМК первого типа, построенные на основе многоканальной `эктроэнцефалограммы головного мозга (ЭЭГ)`. В основе такой системы лежит регистрация электрического потенциала на поверхности головы и его компьютерная обработка.
> 

В ЭЭГ человека прослеживается определенная ритмическая активность, которая делится на несколько групп в зависимости от частоты волн (`альфа-ритм`, `бета-ритм`, `гамма-ритм`, `дельта-ритм`, `мю-ритм`). Для состояния бодрствования характерны бета- и мю-ритмы. Гамма- и дельта-ритмы появляются при засыпании и во сне. Альфа-ритм появляется при закрывании глаз, а также в медитативных состояниях. В связи с этими особенностями ритмов в ИМК наиболее часто используются мю-, бета- и альфа-ритмы.

****
![Основные ритмы ЭЭГ человека](assets/true_rhythms.png)
**Основные ритмы ЭЭГ человека ([2](#pub2))** 

****
![Регистрируемые на ЭЭГ потенциалы, возникающие не в головном мозге - артефакты](assets/wrong_rhythms.png)
**Регистрируемые на ЭЭГ потенциалы, возникающие не в головном мозге - артефакты ([3](#pub3))** 

****
### 1.2.1. Интерфейсы на основе мю-ритма <a name="121"></a>



Интерфейсы на основе мю-ритма ([4](#pub4)), как правило, используют моторное воображение (motor imaginery, MI) – мысленное воображение движений (например, поднятия левой или правой руки), при котором человек не совершает реальных движений. При представлении движений происходит подавление характерного для состояния бодрствования мю-ритма (частотой 7-11 Гц), регистрируемого электродами, расположенными на коже головы в центральных и центрально-височных областях. Пользователя подобным интерфейсом инструктируют, что в момент, когда он хочет отдать команду интерфейсу, он должен представить то или иное движение. Классификатор обучают различать два типа электрической активности – наличие мю-ритма (синхронизация) и отсутствие мю-ритма (десинхронизация, замещение мю-ритма в ЭЭГ менее синхронными низкоамплитудными колебаниями). Таким образом, после обучения классификатора, можно установить, что в момент, когда произошла десинхронизация мю-ритма, пользователь хотел отдать команду, и запрограммировать компьютер на определенные действия, совершаемые в этом случае.

Так, в одном из исследований с применением подобного интерфейса, айтрекинг использовался для отслеживания взгляда пользователя, выбирающего одну из нескольких целей на мониторе компьютера, а моторное воображение – для подтверждения выбора (O’Doherty et al., 2014). В другом исследовании к компьютеру была подключена система управления экзоскелетом руки, который был разработан для больных гемипарезом. С помощью айтрекинга происходило отслеживание намерения пользователя взять тот или иной объект в реальной среде (выбор цели), а моторное воображение использовалось для контроля различных параметров движения руки (скорость, ускорение) и для конечного захвата объекта (Frisoli et al., 2012). Существуют и другие варианты интерфейсов. Интерфейсы, использующие моторное воображение, удобны в использовании, так как обеспечивают интуитивное управление (представил движение – произошло движение, при условии, что интерфейс подключен, например, к роботизированной руке), но требуют достаточно длительного обучения.


****
### 1.2.2. Интерфейсы на основе альфа-ритма <a name="122"></a>

Интерфейсы, использующие альфа-ритм, устроены таким образом, что для отдачи определенной команды нужно закрыть глаза. Пример подобного гибридного интерфейса – система управления роботизированной рукой, в которой саккады использовались для перемещения руки в одном из четырех направлений, а для сжатия руки пользователю необходимо было закрыть глаза, при этом интерфейс улавливал изменение в электроэнцефалограмме (появление альфа-ритма) (Postelnicu et al., 2011). Интерфейсы также вполне успешно работают, но минус достаточно очевиден – при отдаче команды ненадолго теряется зрительная связь с окружающей средой, и, кроме того, подобное управление несколько утомительно. Кроме того, у некоторых людей альфа-ритм слабо выражен, что затрудняет широкое применение интерфейсов, использующих его для управления.


****
### 1.2.3. Интерфейсы на основе SSVEP и айтрекинг <a name="123"></a>

В других гибридных интерфейсах используются зрительные вызванные потенциалы стабильного состояния (SSVEP) и айтрекинг. SSVEP - устойчивые зрительные вызванные потенциалы, которые возникают при стимуляции на частоте от 3,5 до 75 Гц (Beverina et al, 2003), при этом частота потенциалов повторяет частоту предъявления зрительных стимулов. Пользователей данных интерфейсов инструктируют, что для отдачи команды необходимо сосредоточить внимание на зрительном стимуле. Классификатор обучается различать изменения в ЭЭГ при появлении SSVEP на стимул, мигающий с определенной частотой. Один из примеров подобной гибридной системы – система для набора текста, совмещающая в себе SSVEP и айтрекинг (Lee et al., 2013). В этой системе 30 клавиш (буквы английского алфавита и другие кнопки, необходимые для ввода текста) постоянно мигали, каждая на своей частоте, для выбора определенной буквы нужно было сконцентрировать внимание на ней, при этом контролировалось положение взгляда. В случае, если оно сильно не соответствовало положению клавиши, команда напечатать букву не отдавалась.


Другой пример гибридного интерфейса, совмещающий в себе ИМК-SSVEP и айтрекинг – система управления простой игрой, в которой нужно собрать паззл (Kos’Myna, 2013). 

Интерфейсы на основе SSVEP и айтрекинга, в которых используется  большое количество стимулов, в ряде случаев могут вызывать достаточно сильное утомление,  так как пользователю приходится постоянно смотреть на экран, где мигает большое число стимулов на разной частоте. Кроме того, при некоторых условиях они потенциально эпилептогенны.

****
### 1.2.4. Интерфейсы, использующие P300<a name="124"></a>


Компонент Р300 возникает в ответ на неожиданный редко предъявляемый (например, предъявляемый с вероятностью 0.2) значимый стимул, когда он появляется среди часто предъявляемых незначимых стимулов. 

Р300 возникает примерно на 300 мс после предъявления значимого стимула, имеет длительность около 300–400 мс и положительную амплитуду 5–15 мкB. Максимальная амплитуда Р300 наблюдается под центральным электродом. Чем реже предъявляется значимый стимул, тем больше амплитуда Р300. Как правило, требуется несколько усреднений для его выделения из фоновой активности. Р300 зависит от внимания испытуемого, но не от физических параметров стимула.

Р300 — часть сложного потенциала, отражающего процессы переработки информации в мозге, связанные с направленным вниманием при выполнении когнитивной задачи. Физические параметры стимула отражаются в параметрах ранних компонентов вызванных потенциалов. Процессы опознания и классификации стимулов отражаются в компонентах с латентность 96-250 мс после начала стимула, которые принято обозначать как волну N200. Непосредственно с потенциалом P300 связаны завершающие этапы обработки информации - окончательная классификация стимула и принятие решения о действии, связанном со стимулом (Picton, 1992). Существуют некоторые особенности эндогенных вызванных потенциалов на различные зрительные стимулы. Так, некоторых работах показано, что ЗВП на изображения лиц имеют характерные именно для такой стимуляции компоненты (Zhang et al., 2012).

Для выделения P300 используется «оддболл» парадигма или ее модификации – человеку предъявляются целевые и нецелевые стимулы (зрительные или слуховые), причем целевых стимулов на порядок меньше, дается задание считать редкие стимулы про себя. Электроэнцефалограмму разбивают на эпохи относительно подачи редкого стимула, полученные отрезки суммируют, таким образом выделяются вызванные потенциалы, в которых с латентностью около 300 мс появляется волна P300  (цифра «300» в названии как раз и указывает на латентность этой волны). 


Классический интерфейс на основе волны P300 – система для печати, которая представляет собой матриц из букв, в которой последовательно подсвечиваются строки и столбцы (Farwell, Donchin, 1998). Пользователь отмечает про себя (как правило, счетом) появление строки или столбца, содержащего нужную ему букву. Каждая строчка и столбец подсвечивается по нескольку раз, в быстром темпе, что позволяет усреднить реакции на стимулы и выделить, в каких из них наблюдается P300. Таким образом, находя строчку и столбец, на которые удалось выделить такую реакцию, определяют букву, которую хотел напечатать пользователь.


![Позитивный компонент зрительного вызванного потенциала с латентностью около 300 мс (Вызванная волна P300)](assets/P300.jpeg)
**Позитивный компонент зрительного вызванного потенциала с латентностью около 300 мс (Вызванная волна P300) ([3](#pub3))**


Интерфейсы, использующие P300, на данный момент получили широкое распространение, на их основе разрабатываются устройства для парализованных людей (системы для печати букв, инвалидные коляски), игровые приложения (Kaplan et al., 2013), а также ИМК-P300 используются в таких необычных исследованиях, как создание виртуальной реальности и рисование силой мысли (Fazel-Rezai et al., 2012).


****

## 1.3. Облачная платформа *Bluemix* <a name="13"></a>

***Bluemix*** — это открытое облачное предложение типа PaaS
(*Platform-as-a-Service*) на базе проекта с открытым исходным кодом Cloud Foundry. Эта платформа предназначена для разработки и хостинга приложений, а также упрощения задач по управлению инфраструктурой. Она позволяет быстро создавать и развертывать приложения, а также управлять ими.

***Bluemix*** обеспечивает следующие возможности:

-   быстрое и инкрементное составление приложений из сервисов;
-   непрерывное внесение изменений в приложения и обеспечение постоянной доступности;
-   поддержка высокоспециализированных моделей программирования и сервисов для конкретных рабочих нагрузок;
-   встраивание высокой степени управляемости в сервисы и приложения;
-   оптимизация и эластичная адаптация к рабочей нагрузке.


![Каталог компонентов Bluemix](assets/intro04.jpg)
**Каталог компонентов Bluemix**


Платформа *BlueMix* достигает этих целей посредством абстрагирования и скрытия большинства сложностей, традиционно сопутствующих хостингу приложений в облаке и управлению ими в облачной среде. *Bluemix* может быть использована разработчиками для создания и применения самых разных приложений, включая веб-приложения, мобильные приложения, приложения для работы с большими данными, приложения для разумных устройств и т.д. *Bluemix* поддерживает разработку на популярных языках программирования и средах разработки. Java-технологии, средства создания серверных частей для мобильных приложений, мониторинг приложений, технологии с открытым исходным кодом и т. д. — все эти возможности
доступны в облаке как сервисы.

Каталог *Bluemix* содержит большую часть из того, что необходимо для быстрого начала работы, большое количество шаблонов, заранее сконфигурированны наборов сервисов, сред исполнения и примеров кода, готовых к использованию:

-   сред исполнения, в том числе: Liberty for Java, Node.js, Ruby on Rails;
-   веб-сервисов и сервисов приложений, в том числе: Data/Session Cache,  ElasticMQ, Decision, SSO, Log Analysis, Redis, RabbitMQ, Twilio;
-   мобильных сервисов, в том числе: push-уведомлений, Cloud Code,     Mobile Application Management, Mobile Quality Assurance;
-   сервисов управления данными, в том числе: MongoDB, реляционной базы данных от IBM, JSON-базы данных от IBM, MySQL, PostgreSQL, MobileData, Mobile Sync, BLU Data Warehouse, MapReduce;
-   сервисов мониторинга и анализа;
-   сервисов DevOps Services (прежнее название: JazzHub).


****

## 1.4. Краткое описание концепций *Bluemix* <a name="14"></a>


В терминологии *Bluemix* приложение (*application*) — это созданный вами артефакт, т. е. весь программный код (исходный код или исполняемые двоичные файлы), который необходимо запустить или на который необходимо сослаться в процессе исполнения. Мобильные приложения выполняются за пределами среды *Bluemix* и используют сервисы *Bluemix*, представленные приложениями. В случае веб-приложений приложение — это код, загруженный на платформу *Bluemix* с целью хостинга. Кроме того, платформа *Bluemix* способна осуществлять хостинг программного кода приложения, который вы хотите выполнять на внутреннем сервере в среде на базе контейнера.

На рисунке показаны принципы взаимодействия *Bluemix* с клинтскими приложениями.


![Принципы взаимодействия *Bluemix* с клинтскими приложениями](assets/intro05.jpg)
**Принципы взаимодействия *Bluemix* с клинтскими приложениями**


***Сервис (service)*** — это код, работающий на платформе *Bluemix* и предлагающий некоторую функциональность, которую могут использовать приложения. Это может быть готовый сервис, используемый непосредственно — например, push-уведомления для мобильных приложений или эластичное кэширование для веб-приложения. Вы также можете создавать собственные сервисы в диапазоне от простых служебных функций до сложной
бизнес-логики.

***Организация (organization) и пространство (space)*** — это организационные единицы инфраструктуры, способные хранить и отслеживать ресурсы приложения. Организация содержит домены (domain), пространства и пользователей. Пространство содержит приложения и сервисы. По умолчанию используется три пространства: Development (разработка), Production (производство) и Staging (подготовка). Для приложений, которым требуется среда типа PaaS, предоставляются buildpack-пакеты, каждый из которых представляет собой набор скриптов для подготовки кода к исполнению на целевой PaaS-платформе. Buildpack-пакеты, которые включают необходимую вашим приложениям среду исполнения и могут также содержать специализированные инфраструктуры, упрощают развертывание приложения в облаке по сравнению с самостоятельной установкой и конфигурированием среды исполнения.

Использование сервисов в *Bluemix* включает три этапа:
1.  Сообщите платформе *Bluemix*, что вам требуется новый экземпляр сервиса и какое конкретное приложение будет использовать этот новый экземпляр.
2.  *Bluemix* автоматически инициализирует новый экземпляр этого сервиса и свяжет его с приложением.
3.  Приложение взаимодействует с сервисом.

***Пакеты сервисов (Service bundles)*** — это коллекции API-интерфейсов, используемых в конкретных областях. Например, пакет Mobile Services включает сервисы MobileData, Cloud Code, Push и Mobile Application Management. Доступные сервисы и среды исполнения представлены в каталоге Bluemix. Кроме того, вы можете зарегистрировать собственные сервисы.

### 1.4.1. Развертывание и управление приложением <a name="141"></a>

Чтобы развернуть свое приложение, необходимо загрузить его в среду *Bluemix* и указать, сколько экземпляров этого приложения должно исполняться, а затем сконфигурировать *Bluemix*, введя необходимую информацию для поддержки этого приложения.

В случае мобильного приложения среда *Bluemix* содержит артефакт, который представляет серверную часть мобильного приложения — набор сервисов, который использует приложение для взаимодействия с сервером. *Bluemix* поддерживает серверные компоненты мобильного приложения, взаимодействующие с сервисами PushWorks, Cloud Code и Mobile Data, непосредственно из пользовательского интерфейса *Bluemix*.

В случае веб-приложения необходимо предоставить в *Bluemix* соответствующую информацию о среде исполнения и среде разработки, чтобы платформа смогла сформировать надлежащую инфраструктуру для исполнения этого приложения.

При развертывании приложений и управлении ими можно использовать инструмент командной строки cf, веб-интерфейс *Bluemix* или сервисы DevOps Services.

Браузерные и мобильные клиенты — а также другие приложения, развернутые на платформе *Bluemix* и выполняющиеся за ее пределами — взаимодействуют с приложениями, работающими на платформе *Bluemix*, через API-интерфейсы типа REST/HTTP. Каждый клиентский запрос маршрутизируется к одному из экземпляров приложения или составляющих его сервисов. Среды исполнения приложений в *Bluemix* изолированы друг от друга даже тогда, когда они находятся на одной и той же физической машине.

В ходе управления приложениями можно запускать, останавливать, перезапускать экземпляры приложения (или, в случае веб-приложения, изменять их количество), а также изменять объем памяти, используемый приложением. Ключевая конструктивная особенность *Bluemix* — отличные показатели при хостинге масштабируемых приложений и артефактов приложений. На данный момент эта платформа не масштабирует приложение автоматически в соответствии с нагрузкой, поэтому этим процессом необходимо управлять самостоятельно посредством создания или удаления экземпляров при изменении рабочей нагрузки. По этой причине ваши приложения должны сохранять все персистентные данные за пределами приложения в одном из сервисов хранения данных, предоставляемых платформой *Bluemix*. При повторном развертывании приложения после обновления используется тот же процесс, что и при начальном развертывании. *Bluemix* останавливает все исполняющиеся экземпляры и переводит новые экземпляры в рабочее состояние автоматически.

### 1.4.2. Сервисы DevOps Services для *Bluemix* <a name="142"></a>

При использовании DevOps Services требуется лишь несколько простых шагов для организации взаимодействия с другими специалистами с целью планирования, отслеживания и создания программного обеспечения в облаке. Вы можете воспользоваться встроенным в браузер редактором программного кода, который DevOps Services предоставляет для разработки приложений, или использовать DevOps Services с Eclipse, с VisualStudio или с инструментом командной строки Git для написания кода приложения и развертывания его на платформе BlueMix.

При работе с пользовательским интерфейсом, который помогает разработчику быстро добавлять сведения "кто", "что" и "когда" для своего рабочего проекта, требуется потратить всего несколько минут на задание дат, документирование первого сценария применения, назначение одной-двух задач и переход непосредственно к написанию программного кода.

DevOps Services включает встроенные средства управления исходным кодом — Jazz SCM и хостинговый Git. Каждый проект получает свой собственный репозиторий DevOps Services и рабочее пространство, в котором участники этого проекта могут регистрироваться свои изменения, ассоциировать изменения программного кода и просматривать историю недавних изменений. Кроме того, вы можете создать проект DevOps Services и указать на свой репозиторий GitHub.

Вы также можете с легкостью связать элементы работы с изменениями кода в GitHub. Кроме того, для написания кода в Git вы можете использовать имеющиеся у вас инструменты.

Типичными сценариями использования ресурса DevOps Services являются:

-   Создание приложения для анализа данных социальных сетей с использованием Node.js, Node-RED, Express, sentiment и ntwitter.
-   Создание приложения для создания интерактивных опросов в реальном     времени с использованием Node.js, Node-RED, Express, AngularJS и MongoDB.
-   Построение сервисов уведомления с использованием Node.js, Node-RED и MongoDB.
-   Создание приложений для управления аппаратными устройствами c использованием Node-RED и IoT компонент.

### 1.4.3. Среда визуальной разработки JavaScript приложений Node-RED <a name="143"></a>

**Node-RED** - это визуальная drag-and-drop среда разработки JavaScript рантаймов для IoT (неблокирующих приложений, управляемых событиями). Благодаря большому количеству примитивов и возможности быстрой визуальной настройки и созданию новых компонентов, в том числе непосредственно на языке JavaScript, Node-RED может быть использована как непрофессиональными пользователями, так и профессиональными разработчиками для ускорения создания веб-приложений в облаке. Это позволяет использовать Node-RED для взаимодействия с недорогими аппаратными платформами в рамках подхода IoT, перенося основную часть вычислительной нагрузки на облачную платформу. Помимо этого все созданные рантаймы могут быть объединены в библиотеки решений и впоследствии перенесены в другие проекты благодаря функциям экспорта и
импорта.

### 1.4.4. Терминология Node-RED <a name="144"></a>

*Нод (node)* - функционально законченный блок.

*Поток обработки (flow)* - цепь соединенных нодов и соответствующий им конфигурационный нод.

*Входной нод (input node)* - нод, принимающий внешние данные и задающий начало потоку обработки (flow). Входной нод имеет один или несколько выходных портов (output ports).

*Выходной нод (output node)* - нод, завершающий поток обработки и передающий результаты во внешнюю среду.

*Функциональный нод (function node or query node)* - нод, находящийся внутри потока обработки и имеющий один входной порт и один или несколько выходных портов.

*Конифигурационный нод (config node)* - нод, содержащий конфигурационную информацию, используемую в других нодах. Конфигурационный нод не связан портами с другими типами нодов.

*Набор нодов (node set)* - ноды, включенные в связанные js/html файлы (пары соответствующих друг другу файлов, содержащих связанный код JavaScript и HTML). Ошибка в js/html паре приводит к неработоспособности всех нодов набора.

*Модуль нодов (node module)* - множество связанных js/html файлов (и, соответственно, наборов нодов), где каждая пара описана в package.json файле.

*Пакет нодов (node pack)* - коллекция связанных по функциональности нодов, которые могут быть использованы разработчиком в рамках одного проекта.

![Основное окно проекта в Node-RED](assets/intro06.jpg)
**Основное окно проекта в Node-RED**


### 1.4.5. Пример использования Node-RED <a name="145"></a>

Примером эффективного применения технологии Node-RED может служить проект, на разработку которого требуется около 15 минут. Приложение позволяет автоматически отслеживать текущее местоположение мобильного устройства, определяет прогноз погоды и сообщает о нем через твиттер самому пользователю.

![Поток обработки для информирования о прогнозе погоды](assets/intro07.jpg)
**Поток обработки для информирования о прогнозе погоды**


Решение работает следующим образом:

-   Приложение на мобильном телефоне передает телеметрическую информацию о положении устройства в обрабатывающий поток Node-RED.
-   Телеметрическая информация о местоположении преобразуется в twitter сообщение.
-   Сообщение используется для доступа к прогнозу погоды в ноде Forecast.io.
-   Полученный прогноз форматируется в сообщение twitter.
-   Сообщение посылается на твиттер аккаунт пользователя и отображается на мобильной платформе.

Приведенный пример позволяет реализовать логику взаимодействия с использованием протоколов MQTT, HTTP и Twitters API без глубокого погружения в их технические особенности.





# 2. Raspberry Pi <a name="2"></a>
> Raspberry Pi — одноплатный компьютер размером с банковскую карту, изначально разработанный как бюджетная система для обучения информатике, 
впоследствии получивший намного более широкое применение и популярность, чем ожидали его авторы. 
>

![Raspberry PI](assets/raspberry01.jpg)

**Raspberry PI**

## 2.1. Описание <a name="21"></a>
На плате размером с кредитную карту вы найдёте всё то, что можете найти в обычном персональном компьютере: процессор, оперативную память, 
разъёмы HDMI, USB, Ethernet, аналоговые аудио- и видеовыходы. Кроме того, на плате расположены 40 контактов ввода/вывода общего назначения. К 
ним вы сможете подключать периферию для взаимодействия с внешним миром: исполнительные устройства вроде реле и сервомоторов или же любые 
сенсоры; в общем всё, что работает от электричества.

Штатной операционной системой для Raspberry Pi является Linux. Она устанавливается на micro-SD карту, а та в свою очередь — в специальном 
слоте на плате. Если вы не знаете Linux, не стоит пугаться. Напротив: этот компьютер — прекрасная возможность во всём разобраться. Потерять 
данные или сильно напортачить с настройками не так страшно, ведь образ на SD-карте можно восстановить за считанные минуты. После этого можно 
продолжить эксперименты с чистого листа или с определённой контрольной точки.

### Порты и аппаратные интерфейсы <a name="211"></a>
Для подключения монитора или телевизора используются композитный видеовыход или разъём HDMI. Кроме того, заводские OEM ЖК-экраны могут быть 
подключены через интерфейс DSI.
Raspberry Pi 2 Model B предоставляет 4 USB-порта, объединённых внутренним хабом. К ним, помимо всего прочего, можно подключить клавиатуру и 
мышь.

В качестве низкоуровневых интерфейсов доступны:

- 40 портов ввода-вывода общего назначения
- UART (Serial)
- Шина I²C/TWI
- Шина SPI с селектором между двумя устройствами
- Пины питания: 3,3 В, 5 В и земля

Колонки или наушники могут быть подключены через стандартное гнездо для 3,5 мм джеков. Также звук может передаваться через интерфейс HDMI.
На Raspberry Pi Model B+ доступен Ethernet-адаптер на 10/100 Мбит с выходом на стандартное гнездо 8P8C (RJ45).

### 2.1.2. Распиновка платы <a name="212"></a>
![Распиновка Raspberry](assets/raspberry02.jpg)
**Распиновка Raspberry**

### 2.1.3. Питание <a name="213"></a>
Raspberry Pi Model B+ может быть запитана через microUSB-кабель или через пины питания.
Номинальное напряжение питания — 5 В. Компьютер потребляет до 800 мА без внешних устройств.
Аппаратный выключатель питания на плате отсутствует. Для включения компьютера достаточно просто подсоединить кабель питания. Для выключения 
используйте штатную функцию операционной системы.

****
## 2.2. Разбор тестового примера:<a name="22"></a> 

Нам необходимо следующее оборудование:

![](assets/raspberry03.png)

Берем Raspberry и аккуратно достаем карту памяти из прозрачного бокса.

![](assets/raspberry04.png)

Прежде всего нужно установить SD-карту с операционной системой Raspbian в соответствущее гнездо на плате Raspberry. В гнезде плата фиксируется 
благодаря блокирующему механизму. Для надежного закрепления нужно аккуратно вдавить пальцем карту в гнездо.

![](assets/raspberry05.png)

## 2.3. Настройка SSH соединения с Raspberry Pi <a name="23"></a>

Используя ОС Linux выполнить подключение к RPi можно следующим образом:
```
ssh pi@XX.XX.XX.XX
```
где XX.XX.XX.XX - ранее определенный ip адрес устройства. 

Если вы работаете в ОС Windows, то вам нужно воспользоваться программой Putty.
В поле Имя хоста указываем ip адрес Raspberry в сети, порт 22 и тип подключения SSH.

Пароль пользователя pi: raspberry

***
## 2.4. Как узнать адрес Raspberry? <a name="24"></a>

* В Ubuntu выполните команду *sudo nmap –sn < ip-адрес компьютера >/< маска >*.  Пример:

 *sudo nmap -sn 192.168.1.0/24 -p 22*

* В Windows скачайте любое приложение, сканирующее адреса (к примеру, Advanced IP Scanner). Просканируйте сеть, в которой находится компьютер.
* В списке найдите устройство с именем, подобным “Raspberry PI”.
Если вы обнаружите несоклько микрокомпьютеров “Raspberry PI” в вашей сети, вам понадобится узнать т.н. MAC адрес устройства - уникальный идентификатор сетевого устройства, состоящий из 6 байт. Узнать его можно по команде:

```shell
$ ifconfig
$ eth0      Link encap:Ethernet  HWaddr `28:d2:44:69:2a:c8` 
```

Также вы можете определить вашу плату по уникальному имени устройства `hostname` в файле /etc/hosname:
```shell
$ cat /etc/hostame
$ host10
```
В исключительном случае вы можете обнаружить вашу плату опытным путем, отключая и подключая свой Pi к сети.



## 2.5. Установка и запуск VNC сервера <a name="25"></a>

Для установки VNC сервера необходимо выполнить команды:
```
apt-get install tightvncserver
```
При инсталляции установить пароль для подключения к серверу: raspberry.
```
vncserver :1 -geometry 1280x1024 -depth 24
```
Проверить работоспособность сервера, подключившись к RPi с персонального компьютера. Для этого в операционной системе Windows использовать прграмму tightvncclient: [Клиенты](http://sourceforge.net/projects/vnc-tight/files/latest/download)

Для операционной системы Linux можно использовать приложение xtightvncviewer.

Настройки клинета для доступа к серверу:
Сервер: `XX.XX.XX.XX : D` 
где  `XX.XX.XX.XX` – ip адрес платы Raspberry, `D` : номер экрана (в примере  D=1)
Логин: pi
Пароль: raspberry

***
## 2.6. Полезные команды для работы в ОС Raspbian <a name="26"></a>

-   "top" — запуск предустановленного в Raspbian диспетчера задач;
-   "sudo raspi-config" — запуск первоначального меню настроек;
-   "sudo passwd root" — создание пароля для пользователя root;
-   "startx" — запуск графической оболочки;
-   "sudo halt" — выключение RPi;
-   "logout" — выход из системы;
-   "sudo reboot" — перезагрузка RPi;
-   "cd" — переход в необходимую директорию, например, для перехода в директорию /etc/network/ - "cd /etc/network/"
-   "pwd" — путь до текущей директории;
-   "dir" — содержимое текущей директории;
-   "mkdir" — создание директории. Например, "mkdir /home/pitest/" создаст директорию "pitest";
-   "rmdir" — удаление директории. Например, "mdir /home/pitest/" - удаление директории "pitest";
-   "cat" — открыть файл для чтения. Например, "cat /etc/network/interfaces" покажет содержимое файла "interfaces";
-   "nano" — открыть файл для редактирования. Например, "nano
-   /etc/network/interfaces" откроет для редактирования файл "interfaces";
-   "ifconfig" — отобразит текущую конфигурацию сети;
-   "df" — выведет в консоли свободное и используемое дисковое пространство для всех разделов файловой системы;
-   "clear" — очистить экран терминала;
-   "Ctrl"+"Ins" — скопировать выделенное (текст);
-   "Shift"+"Ins" — вставить из буфера (текст);
-   "sudo" — выполнения команд c правами root пользователя. Например, это актуально, если вы зашли под пользователем "pi" и хотите из консоли 
отредактировать какой-нибудь системный файл - "sudo nano путь_до_файла";
-   "Ctrl"+"C" — остановка текущего действия/выход из консольного приложения;
-   "sudo apt-get update" — обновление списка доступных пакетов;
-   "sudo apt-get upgrade" — обновление установленных пакетов;
-   "sudo apt-get install" — установка необходимого пакета. Например, для
установки консольного браузера Links вводим "sudo apt-get install links".

***
## 2.7. Программирование <a name="27"></a>

В качестве языка программирования выбран Python из-за своего удобства работы с базами данных и серверой частью.

в консоли SSH соединения с Raspberry делаем последовательно следующее:

Переход в ваш домашний каталог
```shell
$ cd ~
```
Создание папки для Хакатона
```shell
$ mkdir hackathon
$ cd hackathon
```
Далее можно приступать к написанию кода приема данных от электроэнцефалографа.


****
# 3. Принцип действия электроэнцефалографа<a name="3"></a>


ЭЭГ представляет собой сложный колебательный электрический процесс, который может быть зарегистрирован при расположении электродов на мозге или на поверхности скальпа, и является результатом электрической суммации и фильтрации элементарных процессов, протекающих в нейронах головного мозга.



****
## 3.1. Основы электроэнцефалографии головного мозга человека <a name="31"></a>


Многочисленные исследования показывают, что электрические потенциалы отдельных нейронов головного мозга связаны тесной и достаточно точной количественной зависимостью с информационными процессами. Для того чтобы нейрон генерировал потенциал действия, передающий сообщение другим нейронам или эффекторным органам, необходимо, чтобы собственное его возбуждение достигло определенной пороговой величины.

Уровень возбуждения нейрона определяется суммой возбуждающих и тормозных воздействий, оказываемых на него в данный момент через синапсы. Если сумма возбуждающих воздействий больше суммы тормозных на величину, превышающую пороговый уровень, нейрон генерирует нервный импульс, распространяющийся затем по аксону. Описанным тормозным и возбуждающим процессам в нейроне и его отростках соответствуют определенной формы электрические потенциалы.

Как показано выше, электрическая активность отдельных нервных клеток отражает их функциональную активность по переработке и передаче информации. Отсюда можно сделать заключение, что суммарная ЭЭГ также в преформированном виде отражает функциональную активность, но уже не отдельных нервных клеток, а их громадных популяций, т.е., иначе говоря, функциональную активность мозга. Это положение, получившее многочисленные неоспоримые доказательства, представляется исключительно важным для анализа ЭЭГ, поскольку дает ключ к пониманию того, какие системы мозга определяют внешний вид и внутреннюю организацию ЭЭГ.

![Основные отделы головного мозга человека](assets/brain.png)
**Основные отделы головного мозга человека**


![Применение ЭЭГ для анализа ритмов](assets/brain2.png)
**Применение ЭЭГ для анализа ритмов**

![Активность участков головного мозга человека](assets/brain1.png)
**Активность участков головного мозга человека**


****
## 3.2. Восьмиканальный электроэнцефалограф ИНЭУМ им.И.С.Брука <a name="32"></a>


Электроэнцефалограф производства компании ИНЭУМ им.И.С.Брука представляют собой многоканальные регистрирующие устройства, объединяющие 8 идентичных усилительно-регистрирующих блоков (каналов), позволяющих таким образом регистрировать одномоментно электрическую активность от соответствующего числа пар электродов, установленных на голове обследуемого.

Электроэнцефалограф ООО ИНЭУМ им.И.С.Брука цифрового типа с сухими эоектродами преобразуют ЭЭГ в цифровую форму и вводят ее в микроконтроллер STM32, который управляет  непрерывный процесс регистрации ЭЭГ, одновременно записываемой в память компьютера.

![Электроэнцефалограф ИНЭУМ им.И.С.Брука](assets/eeg.jpg)
**Электроэнцефалограф ИНЭУМ им.И.С.Брука**	


Микроконтроллер STM32 реализует систему генерации управления исполнительными механизмами и потоковую передачу данных по протоколу MODICON MODBUS RTU. 
Протокол реализован на физических линиях интерейса RS232 через микросхему FTDI, транслирущую пакеты RS232 в `USB`. Таким образом, прием и передача пакетов ЭЭГ может босуществяться по интерфейсу USB. 

Для получения доступа к отснятым или уже обработанным данным необходимо выдать ряд команд инициализации, а также команд запросов в формате, представленном ниже:


![Формат пакета запроса](assets/burst.jpg)
**Формат пакета запроса**


Ниже приведен код инициализации электроэнцефалографа. 

```
ser = serial.Serial("/dev/ttyUSB0")
ser.baudrate = 460800

if ser.isOpen():
    ser.close()
ser.open()
ser.isOpen()

# посылаем команду записи в регистр 0x39 значения 0x214
ser.write("/put/memory?address=39&value=214&\r".encode())
time.sleep(5)
ser.write("/put/memory?address=40&value=194&\r".encode())
time.sleep(5)
ser.write("/put/memory?address=41&value=96&\r".encode())
time.sleep(5)
ser.write("/put/memory?address=42&value=0&\r".encode())

# И так далее ....

# завершаем инициализация
ser.write("/put/memory?address=52&value=1&\r".encode())
time.sleep(3)


```



В ответ на команды, электроэнцефалограф входит в режим постоянной генерации пакетов данных. Для обработки пакета необходимо обнаружить 
заголовок `0x01,0x1C,0x20`, посде чего читается количество байт данных (стандарное количество составляе 512 байт). Далее проверяется `CRC`.

Самое главное! Не забывайте сбрасывать буфер последовательного порта перед чтением. В противном случае вы получите данные,пришеддшие некоторое время назад и сохраненные в FIFO буфере. 

```
#Clear all buffers
if state:
	ser.flushInput()
	ser.flushOutput() 

```



![Формат пакета ответа](assets/burst1.jpg)
**Формат пакета ответа**

Код парсера пакета показан ниже:

```
def receive_data_from_eeg():

	
	# массив FiFo
 	global valuechannel1
  	global valuechannel2
  	global valuechannel3
	global learnData
	global education

	valuechannel1.clear()
	valuechannel2.clear()
	valuechannel3.clear()

	#wait 100 ms	
	time.sleep(0.1)
	
	#Clear all buffers
	if state:
  		ser.flushInput()
		ser.flushOutput() 

	begin_time = time.time()
  	buffer_lst = []
	learnData=[]
  	counter = 0
	break_flag = False
  	while not(break_flag) : # Цикл 
	  	data_of_byte = get(3)
	  	header = change3byte(data_of_byte)
	  	headerfirstbyte = int(header[0])
	  	headersecondbyte = int(header[1])
	  	headerthirtbyte = int(header[2])
	  	# Проверка заголок пакета
	   	while headerfirstbyte != 1 and headersecondbyte != 28 and headerthirtbyte != 32:
	    		data_of_byte = data_of_byte[1:]
	    		data_of_byte += get(1)
	    		header_nextbyte = changebyte(data_of_byte[2])
	    		headerfirstbyte = headersecondbyte
	    		headersecondbyte = headerthirtbyte
	    		headerthirtbyte = int(header_nextbyte[0])
	   	if headerfirstbyte == 1 and headersecondbyte == 28 and headerthirtbyte == 32:
	    		data_of_byte = data_of_byte + get(520) 
	    		size = change2byte(data_of_byte[7:9]) #Информация об объеме данных
	    		if int(size[0]) == 512: #Проверка размеров данных
	     			x = 9
	     			data_for_matrix = data_of_byte[0:521] #Данные от 16 сэмплов
	     			crc = data_of_byte[521:523] #CRC
	     			matrix_of_value = [[0] * 16 for i in range(8)]
	     			for i in range(16):
	      				for j in range(8):
						value = change4byte(data_for_matrix[x:x+4])
						x += 4 #Шаг по 4 байта
						buffer_lst.append(int(value[0]))
						matrix_of_value[j][i] = buffer_lst[:] #Ввод данных в массив
						del buffer_lst[:]
	     			crc_check = calc(data_for_matrix)
	     			crc = ''.join([ crc[x:x+2][::-1] for x in range(0, len(crc), 2) ])
	     			crc = change2byteCRC(crc)
	    			if int(crc[0]) == crc_check: #Сравнения CRC
	       				end_time = time.time()
	       				my_time = end_time - begin_time 
	       				if counter < 4 : #Пока не получим 4 пакета (но не менее 500 мс от начала предъявления)
						valuechannel1.append(matrix_of_value[0:15][0])
						valuechannel2.append(matrix_of_value[1:15][0])
						valuechannel3.append(matrix_of_value[2:15][0])
						counter += 1
	       				else: #Иначе отправка данных в Bluemix + очистка FiFo
						# 
						for i in range(4):
							for j in range (16):
								learnData+=valuechannel1[i][j]
								learnData+=valuechannel2[i][j]
								learnData+=valuechannel3[i][j]
						print "__________________"
						print learnData
						print "__________________"
						counter = 0
						background_image=Tk.PhotoImage(file="right.png")
						time.sleep(0.5) #Задержка 500 мс
						begin_time = time.time()
						break_flag = True


```


Код проверки CRC

```
# Преобразование данных
def changebyte(needbyte):
	return  struct.unpack('b', needbyte)
def change2byteCRC(need2byteCRC):
  return  struct.unpack('h', need2byteCRC)
def change2byte(need2byte):
	return  struct.unpack('>h', need2byte)
def change3byte(need3byte):
	return  struct.unpack('BBB', need3byte)
def change4byte(need4byte):
	return  struct.unpack('>i', need4byte)

# Вычисление CRC
def calc(data):
        crc_table=[
0x0000,0xC0C1,0xC181,0x0140,0xC301,0x03C0,0x0280,0xC241,0xC601,0x06C0,0x0780,0xC741,0x0500,0xC5C1,0xC481,0x0440,
0xCC01,0x0CC0,0x0D80,0xCD41,0x0F00,0xCFC1,0xCE81,0x0E40,0x0A00,0xCAC1,0xCB81,0x0B40,0xC901,0x09C0,0x0880,0xC841,
0xD801,0x18C0,0x1980,0xD941,0x1B00,0xDBC1,0xDA81,0x1A40,0x1E00,0xDEC1,0xDF81,0x1F40,0xDD01,0x1DC0,0x1C80,0xDC41,
0x1400,0xD4C1,0xD581,0x1540,0xD701,0x17C0,0x1680,0xD641,0xD201,0x12C0,0x1380,0xD341,0x1100,0xD1C1,0xD081,0x1040,
0xF001,0x30C0,0x3180,0xF141,0x3300,0xF3C1,0xF281,0x3240,0x3600,0xF6C1,0xF781,0x3740,0xF501,0x35C0,0x3480,0xF441,
0x3C00,0xFCC1,0xFD81,0x3D40,0xFF01,0x3FC0,0x3E80,0xFE41,0xFA01,0x3AC0,0x3B80,0xFB41,0x3900,0xF9C1,0xF881,0x3840,
0x2800,0xE8C1,0xE981,0x2940,0xEB01,0x2BC0,0x2A80,0xEA41,0xEE01,0x2EC0,0x2F80,0xEF41,0x2D00,0xEDC1,0xEC81,0x2C40,
0xE401,0x24C0,0x2580,0xE541,0x2700,0xE7C1,0xE681,0x2640,0x2200,0xE2C1,0xE381,0x2340,0xE101,0x21C0,0x2080,0xE041,
0xA001,0x60C0,0x6180,0xA141,0x6300,0xA3C1,0xA281,0x6240,0x6600,0xA6C1,0xA781,0x6740,0xA501,0x65C0,0x6480,0xA441,
0x6C00,0xACC1,0xAD81,0x6D40,0xAF01,0x6FC0,0x6E80,0xAE41,0xAA01,0x6AC0,0x6B80,0xAB41,0x6900,0xA9C1,0xA881,0x6840,
0x7800,0xB8C1,0xB981,0x7940,0xBB01,0x7BC0,0x7A80,0xBA41,0xBE01,0x7EC0,0x7F80,0xBF41,0x7D00,0xBDC1,0xBC81,0x7C40,
0xB401,0x74C0,0x7580,0xB541,0x7700,0xB7C1,0xB681,0x7640,0x7200,0xB2C1,0xB381,0x7340,0xB101,0x71C0,0x7080,0xB041,
0x5000,0x90C1,0x9181,0x5140,0x9301,0x53C0,0x5280,0x9241,0x9601,0x56C0,0x5780,0x9741,0x5500,0x95C1,0x9481,0x5440,
0x9C01,0x5CC0,0x5D80,0x9D41,0x5F00,0x9FC1,0x9E81,0x5E40,0x5A00,0x9AC1,0x9B81,0x5B40,0x9901,0x59C0,0x5880,0x9841,
0x8801,0x48C0,0x4980,0x8941,0x4B00,0x8BC1,0x8A81,0x4A40,0x4E00,0x8EC1,0x8F81,0x4F40,0x8D01,0x4DC0,0x4C80,0x8C41,
0x4400,0x84C1,0x8581,0x4540,0x8701,0x47C0,0x4680,0x8641,0x8201,0x42C0,0x4380,0x8341,0x4100,0x81C1,0x8081,0x4040]

        crc_hi=0xFF
        crc_lo=0xFF

        for w in data:
                index=crc_lo ^ ord(w)
                crc_val=crc_table[index]
                crc_temp=crc_val/256
                crc_val_low=crc_val-(crc_temp*256)
                crc_lo=crc_val_low ^ crc_hi
                crc_hi=crc_temp

        crc=crc_hi*256 +crc_lo
        return crc

```

Для удобства отладки проектов мы записали 60 пакетов данных в файл `eeg.dat`. Чтобы использовать данные из файлов, вместо реальных данных с электроэнцефалографа, неоюбходимо установить переменную `state` в состояние "0". При отладке на энцефалографе не забудьте установить `state = 1`.

```
datafile = "eeg.dat"

# режим работы
# state = 1 	#Данные поступают из электроэнцефалографа
state = 0 	#Данные поступают из файла datafile

if state == 1:
	ser = serial.Serial("/dev/ttyUSB0")


``` 

Выполним тестирование примера:

Войдите в raspberry через консоль `ssh`.

`cd ./hackathon`

`mkdir stage1`

`cd stage1`

`wget https://github.com/alexbmstu/bmstu-hackathon/raw/master/src/stage1/stage1.zip`

`unzip stage1.zip`

`python hackathon.py`

Подключитесь к Вашей raspberry через vnc клиент и начните тестирование.


Проверьте работоспособность Вашего кода для state=0 и для state=1 (на приборе). Должно получится примерно следующее:


![Тестирование приема данных](assets/test1.png)
**Тестирование приема данных**





****
# 4. Нейронные сети<a name="4"></a>

****

## 4.1 Немного теории<a name="41"></a>

Нейронной сетью называется математическая модель, реализующая фукнции искусственного интеллекта путём воспроизведения нервной системы человека. Они используются для решения сложных задач, которые требуют аналитических вычислений, подобных тем, что делает человеческий мозг. К таким задачам относятся, например, классификация, кластеризация, прогнозирование, распознавание и т.д.

Искусственный нейрон представляет собой сумматор входных сигналов, применяющий к полученной взвешенной сумме некоторую простую функцию. Нейрон имеет синапсы - однонаправленные входные связи, соединённые с выходами других нейронов, а также аксон - выходную связь.
![Схема искусственного нейрона](assets/artificial-neuron.PNG)
 
Текущее состояние нейрона определяется взвешенной суммой его входов (см. схему). Выход нейрона определяется его активационной функцией.

Совокупность нейронов, расположенных на одном уровне в нейронной сети, называется слоем. В общем случае нейронная сеть включает в себя входной, выходной и промежуточные слои. Нейроны входного и выходного слоёв, как правило, имеют линейную функцию активации и предназначены для приёма и передачи данных. Нейроны промежуточных слоёв - нелинейные; их функцией активации чаще всего является сигмоид (логистическая функция):
![equation](https://latex.codecogs.com/png.latex?f%28x%29%20%3D%20%5Cfrac%7B1%7D%7B1%20&plus;%20e%5E%7B-%5Calpha%20x%7D%7D)

На схеме показан пример полносвязной нейронной сети, имеющей входной, промежуточный и выходной слои.
![Схема нейронной сети](assets/neuro_scheme.png)

Нейронная сеть обучаема. В процессе обучения параметры сети настраиваются в соответствии с обучающими наборами данных, моделирующих среду, в которой будет функционировать сеть. В зависимости от способа подстройки параметров различают обучение с учителем и без учителя.

Обучение с учителем представляет собой предъявление сети выборки обучающих примеров. Каждый образец подаётся на входы сети, проходит обработку и перерабатывается в выходной сигнал, который сравнивается с эталонным значением. Затем в зависимости от степени расхождения реального и идеального результатов изменяются весовые коэффициенты связей внутри сети. Обучение длится до тех пор, пока ошибка по всему обучающему массиву не достигнет приемлемо низкого уровня.

При обучении без учителя обучающее множество состоит лишь из входных векторов. Алгоритм обучения подстраивает веса внутри сети так, чтобы предъявление достаточно близких входных векторов давало одинаковые результаты.

Почитать подробнее про нейронные сети можно [здесь](http://www.aiportal.ru/articles/neural-networks "Статьи о нейронных сетях").

****

## 4.2 Как выбрать топологию нейронной сети? <a name="42"></a>

В первую очередь нужно проанализировать задачу, для решения которой создаётся нейронная сеть.

Наша задача - обработать сигналы, поступающие от ЭЭГ, и определить, какой реакции они соответствуют. Сигнал от ЭЭГ представляет собой совокупность из 64 целочисленных значений, которые мы будем называть признаками. На выходе нейронной сети нам нужно получать вектор значений, который будет обозначать тип распознанной реакции. Единичное значение i-го элемента выходного вектора означает, что обнаружена соответствующая ему i-я реакция. Также может быть, что выходной вектор состоит из нулей: это значит, что на вход подан набор признаков, описывающий неизвестную сети реакцию.

Мы будем распознавать реакции двух типов: "Влево" и "Вправо".

За основу возьмём многослойный перцептрон - модель сенсорного нейрона, способного воспринимать, анализировать и реагировать на раздражение. Число слоёв в общем случае определяется требуемой точностью и производительностью вычислений.

Существует теорема о количестве слоёв, согласно которой:

1. Если функция определена на конечном множестве точек, то 3-ехслойный перцептрон способен ее апроксимировать.

2. Если функция непрерывна и определена на компактной области, то 3-ехслойный перцептрон способен ее апроксимировать.

3. Остальные функции, которым могут быть обучены нейронные сети, могут быть апроксимированы 4-ехслойным перцетроном.

На практике может использоваться и большее число слоёв, но с его увеличением возрастает сложность сети, время её обучения и работы и объём требуемых ресурсов. Здесь мы рассмотрим 4-слойный перцептрон.

Для лучшей работы сети входные данные нужно нормировать - привести к отрезку [0, 1]. Проще всего сделать это по следующей формуле:

![equation](https://latex.codecogs.com/png.latex?x_%7Bnorm%7D%20%3D%20%5Cfrac%7Bx%20-%20x_%7Bmin%7D%7D%7Bx_%7Bmax%7D%20-%20x_%7Bmin%7D%7D)

Число нейронов во входном слое совпадает с числом входных признаков: i = 64.

Число нейронов в выходном слое совпадает с числом распознаваемых реакций: o = 2.

Число нейронов в промежуточных слоях, как правило, определяется экспериментально, однако существуют эмпирически выведенные [рекомендации](http://mei06.narod.ru/sem7/iis/shpora/page2_9.htm) для 4-слойного перцептрона:

![equation](https://latex.codecogs.com/png.latex?r%20%3D%20%5Csqrt%5B3%5D%7B%5Cfrac%7Bi%7D%7Bo%7D%7D%20%5Capprox%203.17)

![equation](https://latex.codecogs.com/png.latex?k_1%20%3D%20o%20%5Ccdot%20r%5E2%20%5Capprox%2020)

![equation](https://latex.codecogs.com/png.latex?k_1%20%3D%20o%20%5Ccdot%20r%5E2%20%5Capprox%2020)

Выберем в качестве функции активации нейронов скрытых слоёв сигмоид.

Обучать сеть будем по алгоритму обратного распространения ошибки. Этот метод относится к классу обучения с учителем. Краткое разъяснение принципов работы этого алгоритма изложено [здесь](http://www.aiportal.ru/articles/neural-networks/back-propagation.html "Алгоритм обратного распространения ошибки").

Этот базовый проект можно улучшить, меняя число слоёв, число нейронов в скрытых слоях, активационные функции, способ обучения и многое другое. О том, как это сделать, а также о том, как построить базовый вариант - следующий раздел.

****

## 4.3 Бибилиотека PyBrain <a name="43"></a>

PyBrain предоставляет инструментарий для работы с нейронными сетями на языке Python. Документация по PyBrain находится [здесь](http://pybrain.org/docs/index.html "Документация PyBrain").

Приведём пример работы с нейронной сетью с помощью PyBrain.

PyBrain подключается при помощи следующей директивы:

```
import pybrain
```

Самый простой способ создать сеть - воспользоваться функцией buildNetwork:

```
net = buildNetwork(64, 20, 6, 2, bias=True, hiddenclass=SigmoidLayer)
```

Рассмотрим более подробно, что происходит при создании сети:

```
def constructPerceptron (name, numNeurons):
    """Возвращает необученную сеть

    Аргументы:
    name -- имя сети, строка
    numNeurons -- число нейронов в каждом слое, список из целых чисел

    """
    # Создаём сеть
    net = FeedForwardNetwork(name)
    # Создаём слои и добавляем их в сеть
    prevLayer = None
    newLayer = None
    for i, val in enumerate(numNeurons):
        # Если слой входной, он линейный
        if (i == 0): 
            newLayer = LinearLayer(val, 'input')
            net.addInputModule(newLayer)
            prevLayer = newLayer
        # Если слой выходной, он линейный    
        elif (i == len(numNeurons) - 1):
            newLayer = LinearLayer(val, 'output')
            net.addOutputModule(newLayer)
        # Иначе - слой сигмоидный   
        else:
            newLayer = SigmoidLayer(val, 'hidden_' + str(i))
            net.addModule(newLayer)    
        # Если слой не входной, создаём связь между новым и предыдущим слоями
        if (i > 0):
            conn = FullConnection(prevLayer, newLayer, 'conn_' + str(i))
            net.addConnection(conn)
            prevLayer = newLayer
    # Готовим сеть к активации, упорядочивая её внутреннюю структуру        
    net.sortModules()
    # Готово
    return net
```

Далее нам нужно обучить сеть. Для этого необходимо получить обучающую выборку и преобразовать её к требуемому формату.

Каждая обучающая пара состоит из двух элементов: вектора признаков (64 числа) и выходного вектора-образца (2 числа). Фактически оба эти элемента - кортежи из чисел, например, такие: i_data = (0.5, 1, 0, 0.2, ..., 0.7); o_data = (0, 1). 

Объединим вектор признаков и вектор результата в единый кортеж и получим обучающую пару: learnPair = (i_data, o_data).

Наконец, объединим все обучающие пары в список: learnData = [learnPair_1, learnPair_2, ..., learnPair_N].

В таком формате нужно предоставить обучающее множество функции, которая создаст из него dataset PyBrain:

```
def constructDataset (name, learnData):
    """Возвращает обучающую выборку в формате PyBrain

    Аргументы:
    name -- имя набора данных, строка
    learnData -- данные для обучения: список кортежей типа "входные признаки - выходной вектор"

    """
    # Вычисляем размерность входных данных
    dimIn = len(learnData[0][0])
    dimOut = len (learnData[0][1])
    ds = SupervisedDataSet(dimIn, dimOut)
    for d in learnData:
        ds.addSample(d[0], d[1])
    return ds
```

Теперь сеть можно обучать. Будем тренировать сеть на заданном наборе в течение одной эпохи, чтобы избежать переобучения. Чтобы следить за качеством обучения, будем также получать оценку ошибки.

```
def trainNetwork (net, trainData):
    """Возвращает сеть, прошедшую 1 эпоху обучения, и оценку ошибки

    Аргументы:
    net - нейронная сеть, PyBrain network
    trainData -- обучающий набор данных, PyBrain dataset

    """
	  # Трейнер для обучения с учителем
    trainer = BackpropTrainer(net, trainData)
	  # Запускаем трейнер на 1 эпоху и запоминаем оценку ошибки 
    coef = trainer.train()
    return (net, coef)
```

Простейший сценарий создания, обучения и использования сети выглядит так:

```
# Инициализация сети
n = constructPerceptron('perc', [64, 20, 6, 2]) # Создаём перцептрон
# Формирование обучающей выборки
# Данные для обучения data поступают от ЭЭГ в описанном выше формате - списке обучающих пар
ds = constructDataset('data', data)
# Запуск 1 полной эпохи обучения
(trained_net, err) = trainNetwork (n, ds)
# Активизируем сеть! На вход подаем i_vec - список из 64 чисел - вектор входных признаков
print(trained_net.activate(i_vec))
```

Сеть можно экспортировать и импортировать в виде xml-файла.

```
def saveNetwork (net, name):
    """Экспорт нейронной сети в файл

    Аргументы:
    net - нейронная сеть, PyBrain network
    name -- имя файла, строка

    """
    NetworkWriter.writeToFile(net, name)

def importNetwork (name):
    """Возвращает импортированную из файла нейронную сеть

    Аргументы:
    name - имя файла, строка

    """
    return NetworkReader.readFrom(name)
	
# Сохранить сеть
saveNetwork(n, 'net.xml')
# Импортировать сеть
new_n = importNetwork('net.xml')
```

Любой объект библиотеки PyBrain можно распечатать при помощи функции print().

Чтобы изменить число слоёв или число нейронов в слоях сети, нужно подать соответствующий список чисел на вход функции, формирующей сеть.

Чтобы изменить типы скрытых слоёв, достаточно указать другое имя типа слоя при создании сети, например, TanhLayer - слой с активационной функцией в виде гиперболического тангенса.

PyBrain предоставляет также обширные возможности для обучения сети. Можно обучать сеть до достижения сходимости, применяя другой метод объекта trainer:

```
trainer.trainUntilConvergence()
```

Можно выбрать другой алгоритм обучения, меняя классы объектов dataset и trainer.

Эти и другие возможности библиотеки PyBrain описаны в [документации](http://pybrain.org/docs/index.html "Документация PyBrain").


Приступим к обучению нейронной сети и тестированию электроэгнцефалографа.

Войдите в raspberry через консоль `ssh`.

`cd ./hackathon`

`mkdir stage2`

`cd stage2`

`wget https://github.com/alexbmstu/bmstu-hackathon/raw/master/src/stage2/stage2.zip`

`unzip stage2.zip`

`python hackathon.py`

Подключитесь к Вашей raspberry через vnc клиент и начните тестирование.

Проверьте работоспособность Вашего кода для state=0 и для state=1 (на приборе). 

Чтобы не обучать нейронную сеть каждый раз, вы можете добавить код, экспортирующий и импортирующий настройки в виде xml-файла. Вы также можете менять параметры сети, изменяя количество слоев и количество нейронов на каждом слое.

Далее приступим у управлению движением в 3D модели.





# Работа с IBM Bluemix <a name="5"></a>
## Регистрация в Bluemix <a name="51"></a>

Для начала переходим по ссылке https://console.ng.bluemix.net/.

В правом верхнем углу выбираем Sign UP.

![](assets/Bluemix1.JPG)

Заполняем форму и создаем аккаунт. Переходим на почту, указанную при регистрации и подтверждаем свой аккаунт.
Затем выполняем вход в созданный аккаунт (Log In на стартовой странице Bluemix).
После входа всплывет окно:

![](assets/Bluemix2.JPG)

Здесь надо выбрать, где будет расположено приложение,  а также ввести название организации. В качестве места расположения выберите US South. После выбора места и ввода названия организации, также будет предложено ввести имя пространства приложения, дадим имя пространству dev.
На этом регистрация и настройка аккаунта закончена.

## Создание приложения Node.js <a name="52"></a>

*Для данного этапа требуются установленные Node.js, Cloud Foundry CLI и Bluemix CLI. Подробности по ссылке https://console.ng.bluemix.net/docs/starters/install_cli.html*

Создадим примитивный вебсервер, используя Node.js.
Для этого создадим новую папку с предполагаемым именем будущего веб-приложения.(например mqttListener). Запускаем консоль Windows и переходим в только что созданную папку. Создадим файл app.js.(главный файл сервера) и  файл package.json, который будет содержать все зависимости (dependencies, названия необходимых пакетов). Это нужно для того, чтобы при сборке проекта в среде Bluemix, самой средой были установлены требуемые пакеты. Для создания package.json  прописать в консоли npm init и согласиться на все предложенные пункты без изменений (прим. В поле name недопустимы заглавные буквы).

Затем открываем любым текстовым редактором файл package и в поле scripts заменяем прописанное на:

    "start": "node ./app.js"
    
Это требуется для Bluemix, чтобы среда знала, какой файл запустить первым.
Для развертывания сервера будет использован npm пакет express. js (подробнее http://expressjs.com/) . Чтобы тестировать приложение на localhost, надо установить данный пакет. Для этого в консоли пропишем npm install express –save. Команда –save сразу запишет наш пакет в зависимости(dependencies) в файле package.json. При успешной установке появится папка node_modules.
В файле app.js пропишем:
```javascript
var express = require('express'),
	  app = express();


app.get('/', function (req, res) {
	 return res.send("App is working");
  });

//process.env.VCAP_APP_PORT for Bluemix instead of 3000
app.listen(process.env.VCAP_APP_PORT,function(){
	console.log("Start on 3000");
});
```
*Примечание: для того, чтобы приложение запускалось в Bluemix, первый параметр функции listen должен принимать значение process.env.VCAP_APP_PORT, однако для локального запуска сервера нужно прописать лишь номер порта, например 3000.*

Теперь наш мини-сервер готов к заливке в Bluemix.
Для начала надо залогиниться в Bluemix с помощью консоли Cloud Foundry.
Пропишем в консоли cf login. Затем вводим емейл и пароль нашего аккаунта при регистрации.

![](assets/Bluemix3.JPG)

Затем, находясь в папке с нашим проектом пишем: cf push %НазваниеПроекта. 
 В моем случае cf push mqttListener.  *Примечание:  консоль может поругаться, что название уже занято, выберите незанятое.*
 
После данной команды будут произведены операции создания проекта в среде Bluemix, его сборка, а также запуск.
Если перейти по ссылке https://console.ng.bluemix.net/dashboard/applications, то можно увидеть, что теперь появилось новое приложение. Кликая по ссылке в разделе Route, можно убедиться, что приложение работает.

## Подключение сервиса Watson IOT <a name="53"></a>

В разделе All applications (https://console.ng.bluemix.net/dashboard/applications)  щелкнем по Create service:

![](assets/Bluemix4.JPG)

Слева в разделе Services выберем Internet of Things и выберем сервис Internet of Things Platform:

![](assets/Bluemix5.JPG)

Ничего не изменяя, кликаем на Create. В итоге попадем на панель IOT. Сервис IOT подключен. 

## Принципы обмена MQTT-сообщениями в Bluemix и создание MQTT Device и MQTT API key <a name="54"></a>

Сервис Watson IOT предоставляет встроенного MQTT брокера.

Обмен MQTT сообщениями в Bluemix осуществляется в соответствии со схемой:

![](assets/Bluemix6.JPG)

**Пояснения к схеме.**

В среде Bluemix существует 2 вида MQTT клиентов, которые обмениваются сообщениями через брокера: device-клиент и application-клиент. У каждого из них свои принципы обмена сообщениями и для осуществления данных операций нужны разные реквизиты (credentials, о них будет рассказано ниже). Все MQTT-сообщения в Bluemix можно разделить на 2 вида: команды и непосредственная информация. Для обмена сообщениями MQTT брокер в Bluemix предоставляет 2 вида каналов, по одному на каждый вид сообщения: канал для команд (command thread) и канал для данных с датчиков (events thread).

Работа обоих видов клиентов начинается с подключения к брокеру, после этого каждый клиент может совершать операции, которые различаются в зависимости от типа клиента.

Клиенты-девайсы (датчики и т.п.) могут отправлять данные (publish events) на брокера по каналу данных и подписываться (subscribe) на канал команд, в который приходят команды от клиента-приложения.

Клиенты-приложения (в этой роли будет выступать наше веб приложение) могут подписываться (subscribe)на канал данных, которые приходят от датчиков, а также отправлять команды (publish commands) в канал команд.

Примечание: MQTT-сообщения, т.е. данные с датчиков и команды от приложений описаны в формате json. 
Пример данных с датчика:
```
{
	“sensorType” : ”temperature”,
	“value” : “25”
}
```
Пример команды от приложения:
```
{
	“command” : ”setMaxValue”
}
```
Итак, для того, чтобы работать с MQTT брокером, надо создать MQTT device и MQTT API key.

После создания сервиса в панели сервиса в разделе Connect your Devices выберите Launch dashboard. Откроется панель администрирования сервиса IOT.
На панели слева выбираем Devices. Далее нам нужно создать тип нашего будущего девайса. Для этого кликнем на Device types и затем на Create type:

![](assets/Bluemix7.jpg)

Выбираем Create device type. В поле name вводим название типа нашего устройства – MQTTDevice. **_Важно: запомните название типа, оно будет использоваться далее._**
Далее оставляем все без изменений, нажимаем на Next и в итоге на Create. В результате создастся новый тип девайса, это отобразится на панели.

Теперь создадим непосредственный девайс с нашим свежесозданным типом. Для этого переходим во вкладку Browse и выбираем Add Device.
В появившемся окне кликаем по Choose Device Type, выбираем созданный тип и кликаем Next.
В поле Device ID запишем ID устройства (придумываем сами, например: aabbccddee12), кликаем Next->Next->Next->Add.

**_Важный этап: запишите реквизиты устройства(credentials), которые показались после нажатия на Add, больше _возможности их увидеть не будет._**

Таким образом, был добавлен девайс, к которому будут подключаться реальные устройства.

![](assets/Bluemix8.JPG)

Теперь нужно создать API key для того, чтобы клиенты-приложения также могли подключаться к брокеру. На левой боковой панели выбираем раздел APPS. Затем кликаем по Generate API key.

**_Важно: запишите информацию о API key, позже ее невозможно будет снова увидеть._** Кликаем по Generate.

В результате этапа 4 были созданы реквизиты для подключения к брокеру клиента-девайса и клиента-приложения. 

## Описание подключения к MQTT брокеру и проверка передачи MQTT сообщений с помощью MQTTlens <a name="55"></a>

*Для более глубокого понимания можно прочитать статью https://www.ibm.com/developerworks/cloud/library/cl-mqtt-bluemix-iot-node-red-app/*

Подключение к брокеру использует аутентификацию.  
Для подключения к брокеру со стороны девайс-клиента нужны опции:

1) Hostname:  
```
tcp://< OrganizationID >.messaging.internetofthings.ibmcloud.com
```
OrganizationID – из реквизитов при создании девайса в сервисе IOT(см.этап 4)  


2) Client ID:  
```
d:< OrganizationID >:< DEVICETYPE >:< DEVICEID >
```
deviceType - созданный тип устройства.  
deviceID - ID созданного устройства.  

3) Username: use-token-auth

4) Password: < токен, полученный при создании девайса в сервисе IOT >


 
Подключение со стороны клиента-приложения:

1) Hostname: аналогично устройству  
2) Client ID:  
```
a:< OrganizationID >:< app-id >  
```
appID - идентификатор приложения. Может быть любым, например myApp  


3) Username: < API Key >  
Api Key - получили при создании ключа в IOT Platform в разделе APPS (см.этап 4).

4) Password: < токен, полученный при создании ключа в IOT Platform >  
  
  
После подключения к брокеру клиенты могут отправлять сообщения в каналы, либо подписываться на каналы.

Путь **канала данных для публикации(!)** устройством:  
```
iot-2/evt/<event-id>/fmt/<format>
```

EventID - любой идентификатор процесса ( например mySensor)  
format - формат переданного сообщения, в данном случае нужно json.  

**Для подписки(!)** на канал данных **со стороны приложения:**
```
iot-2/type/<type-id>/id/<device-id>/evt/<event-id>/fmt/<format-id>
```

type-id - название типа нашего устройства, например: MQTTDevice  
device-id  - идентификатор устройства, который можно найти в реквизитах девайса(credentials) из этапа 4.  
event-id  - eventId из пути публикации устройством.  
formatid - формат принятого сообщения, в данном случае json.  

**Для публикации клиентом-приложением(!)** команд в канал команд: 
```
iot-2/type/<type-id>/id/<device-id>/cmd/<cmd-id>/fmt/<format-id>  
```

type-id - название типа нашего устройства, например: MQTTDevice  
device-id  - идентификатор устройства, который можно найти в реквизитах девайса(credentials) из этапа 4.  
cmd-id – любой идентификатор команды, задаем сами (например getSmth)  
formatid - формат принятого сообщения, в данном случае json.  


**Для подписки** на канал команд **клиентом-девайсом**: 
```
iot-2/cmd/<cmd-id>/fmt/<format-id>.   
```

cmd-id – любой идентификатор команды, задаем сами (например getSmth).  
formatid - формат принятого сообщения, в данном случае json.  
  
  
Для проверки корректности передачи MQTT сообщений существует удобный сервис для Google Chrome- MQTTlens.  

![](assets/Bluemix9.JPG)

После установки MQTTlens, создадим новое подключение (+ рядом с Connections):

![](assets/Bluemix10.JPG)

Заполняя поля вышеописанным способом, создадим подключение сначала для девайс клиента, затем для клиента-приложения.  
Пример заполнения настроек (для клиента-девайса):  

![](assets/Bluemix11.JPG)

Пример заполнения настроек (для клиента-приложения):

![](assets/Bluemix12.JPG)

Затем подписываемся клиентом-приложением на команды, а клиентом-девайсом публикуем команды (в соответствии с описанным выше в начале этапа 5).  
В результате замечаем внизу окна принятые клиентом-приложением MQTT-сообщения:  

![](assets/Bluemix13.JPG)

## //ToDo Визуализация данных ЭЭГ <a name="56"></a>


# 5. Тренажер управления инвалидной коляской <a name="5"></a>

****
## 5.1 Установка и настройка инструментов для работы с Bluemix<a name="51"></a>

  Для публикации проекта в облаке IBM Bluemix необходимо:

* Зарегистрироваться в Bluemix, выбрав в качестве региона GB

* Установить Docker для локального тестирования проекта, $ bx build & run будет собирать и запускать контейнер по Dockerfile из директории проекта

### 5.1.1 О Docker<a name="511"></a>
  Docker- программное обеспечение для автоматизации развёртывания и управления приложениями в среде виртуализации на уровне операционной системы; позволяет «упаковать» приложение со всем его окружением и зависимостями в контейнер, а также предоставляет среду по управлению контейнерами.

  Простыми словами, Docker это инструмент, который позволяет разработчикам, системными администраторам и другим специалистам разворачивать их приложения в песочнице (которые называются контейнерами), для запуска на целевой операционной системе, например, Linux. Ключевое преимущество Docker в том, что он позволяет пользователям упаковать приложение со всеми его зависимостями в стандартизированный модуль для разработки, таким образом, Docker избавляет от возможных ошибок системного администратора сервера. В отличие от виртуальных машин, контейнеры не создают дополнительной нагрузки, поэтому с ними можно использовать систему и ресурсы более эффективно.
  
  * Инструкция по установке `Docker` на `Ubuntu 16.04`: https://losst.ru/ustanovka-docker-na-ubuntu-16-04

### 5.1.2. Установка Bluemix CLI <a name="512"></a>
* Скачиваем и устанавливаем Bluemix CLI (bx cli):
  ```shell
  $ tar -xvf Bluemix_CLI.tar.gz
  $ cd Bluemix_CLI
  $ sudo ./install_bluemix_cli
  ```
* Теперь нам доступны команды bx - проверим: `$ bx --version`

* Логинимся под учетной записью IBM Bluemix:
  `$ bx login`
  
* Установим `dev` пакет для `bx`: https://console.bluemix.net/docs/cloudnative/dev_cli.html#developercli
`$ curl -sL https://ibm.biz/idt-installer | bash`  
  
* Подробнее о работе с Bluemix CLI:
https://console.bluemix.net/docs/cli/reference/bluemix_cli/get_started.html#getting-started
https://console.bluemix.net/docs/cli/reference/bluemix_cli/download_cli.html#download_install

### 5.1.3. Локальная сборка тестового проекта  <a name="513"></a>
* После установки `dev` пакета выбираем `Node.js` приложение из списка Starter Kit Bluemix: https://console.bluemix.net/developer/appservice/starter-kits

  Подробнее: https://console.bluemix.net/docs/cloudnative/tutorial_bff.html#code

* Нажимаем на Generate code и скачиваем архив с файлами тестового `hello world` приложения.
* Протестируем работоспособность приложения, развернув его локально. Для этого создадим и запустим контейнер:
```
bx dev build
bx dev run
```
* После этого вы сможете посмотреть результат запуска приложения в браузере: `localhost:3000`

  Выведем `hello world!` на стартовой странице приложения: в файле проекта `public/index.html` добавим
  
  `<h1> HELLO IBM! </h1>`

* Чтобы остановить контейнер: `Ctrl + С`

### 5.1.4. Публикации проекта в облаке Bluemix  <a name="514"></a>
* Настроим параметры ORG и SPACE (ключи `-o` и `-s`) в `bx` в соответствии с данными в Bluemix аккаунте:
`bx target -o Brainstormv2 -s space1`

  Должно получиться что-то подобное:
`$ bx login`
```
Authenticating...
OK
...
API endpoint:     https://api.eu-gb.bluemix.net (API version: 2.75.0)   
Region:           eu-gb   
User:             akenoq@yandex.ru   
Account:          BMSTU (eb7fb19a1c1e905a97abccf90b1d2d0b)   
Resource group:   Default   
Org:                 
Space:               
Tip: If you are managing Cloud Foundry applications and services
- Use 'bx target --cf' to target Cloud Foundry org/space interactively, or use 'bx target -o ORG -s SPACE' to target the org/space.
- Use 'bx cf' if you want to run the Cloud Foundry CLI with current Bluemix CLI context.
```

`$ bx target -o Brainstormv2 -s space1`
```
Targeted org Brainstormv2
Targeted space space1
                     
API endpoint:     https://api.eu-gb.bluemix.net (API version: 2.75.0)   
Region:           eu-gb   
User:             akenoq@yandex.ru   
Account:          BMSTU (eb7fb19a1c1e905a97abccf90b1d2d0b)   
Resource group:   Default   
Org:              Brainstormv2   
Space:            space1   
```
`$ bx dev deploy`

* Результат публикации можно посмотреть, перейдя по ссылке на ваше приложение. Ссылку можно найти в панели управления приложениями `Dashboard`: https://console.bluemix.net/dashboard/

### 5.1.5. Создание своего проекта  <a name="515"></a>
* Теперь попробуем опубликовать свое приложение.
  Заменим все директории со статикой в директории скачанного примера на свои, в примере ниже папка static
  + заменим package.json и webpack.config.js
  
  Пример package.json без сборobrf webpack:
  ```
  {
  "name": "socket-server",
  "version": "1.0.0",
  "description": "",
  "main": "index.js",
  "scripts": {
    "start": "node index.js",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "express": "^4.16.2",
    "http": "0.0.0",
    "request": "^2.83.0",
    "ws": "^3.3.1"
  }
  ``` 
  
  
  Пример содержимого в директории с готовым к развертыванию проектом:
`
ibm-project$ ls -1

cli-config.yml
Dockerfile
Dockerfile-tools
idt.js
index.js
LICENSE
manifest.yml
node_modules
node_modules_linux
package.json
README.md
RELEASE
static
webpack.config.js
`

* Проверим локально корректность получившегося проекта:
```
bx dev build
bx dev run
```
* Публикуем в облаке:
```
bx dev deploy
```

****
## 5.2 Работа с 3D-тренажером <a name="52"></a>

1. Скачиваем архив: https://github.com/maxim218/Socket_And_Client_3dWorld/

  * Директория world3D - сокет-клиент 3D-тренажер
  
    => вы можете опубликовать его в своем Bluemix, следуя инструкции 6.1
  
    => тестовый 3D-тренажер доступен по ссылке: https://3d-world-ws-host.eu-gb.mybluemix.net/
    
  * Директория NodeSocket - сокет-сервер, который будет расположен на вашем локальном компьютере. Да-да, это новый тренд :)
  
    => для его запуска необходимо выполнить команды: `npm install` - для подгрузки зависимостей и `node index.js` для запуска сервера на `localhost:5007`
 2. Управление
 
    Управляющие сигналы в формате `W`, `A`, `S`, `D` + `__` ваша программа распознвания должна писать в файл keysFile.txt (сейчас там есть тестовый клиент Qt SignalsSender) => данные из этого файла по сокет-соединению передаются на 3D-тренажер.
    
    Примеры данных в файле: `W__`, `A__` или одноременно `WA__`
 


# //ToDo Основной алгоритм управления системой и тестирование проекта ИМК <a name="7"></a>

****
## //ToDo <a name="71"></a>

****
## //ToDo <a name="72"></a>

****
## //ToDo <a name="73"></a>

****
# Дополнительная литература <a name="a001"></a>

<a name="pub1">[1]</a> А. А. Фролов, В. Ю. Рощин // ИНТЕРФЕЙС МОЗГ-КОМПЬЮТЕР. РЕАЛЬНОСТЬ И ПЕРСПЕКТИВЫ. N6. Нейронные сети. 2017

<a name="pub2">[2]</a> http://www.drmueller-healthpsychology.com/What_is_AVE.html

<a name="pub3">[3]</a> В.Н.Кирой. Интерфейс мозг-компьютер (история, перспективы). Ростов-на-Дону, Издательство университета. 2011 г., 48 рис., 240 с.

<a name="pub4">[4]</a> К.Д.Вигасина. Разработка гибридного интерфейса глаз-мозг-компьютер, использующего саккады в ответ на стимулы. Дипломный проект. МГУ, Кафедра ВНД, 2015

<a name="pub5">[5]</a> http://brain.bio.msu.ru/bci_r.htm



